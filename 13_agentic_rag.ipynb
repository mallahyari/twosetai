{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b1750a71-a471-4a24-b490-559dc45bce6d",
   "metadata": {},
   "source": [
    "# Agentic RAG\n",
    "\n",
    "The main points of an Agent-based RAG solution are:\n",
    "\n",
    "- **Agentic**: The system is autonomous, making decisions and taking actions based on the context of the interaction.\n",
    "- **RAG (Retrieval-Augmented Generation):** Combines information retrieval from the knowledge base with the LLM’s generative capabilities."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41b1e46a-2181-4f5c-9c01-2359346e8e54",
   "metadata": {},
   "source": [
    "## System architecture\n",
    "\n",
    "\n",
    "![agentic rag](images/agentic_rag_0.png)\n",
    "![agentic rag](images/agentic_rag_1.png)\n",
    "![agentic rag](images/agentic_rag_2.png)\n",
    "![agentic rag](images/agentic_rag_3.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9af0e2c-3d72-448d-b065-9e643abff513",
   "metadata": {},
   "source": [
    "## Langchain Code\n",
    "\n",
    "![](images/langchain_agentic_rag.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6f7bc5e-a02c-4db9-80a1-273f481e4d0b",
   "metadata": {},
   "source": [
    "## Read and load PDF files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8f2ccfda-74d5-4343-bbcc-9abff63b5cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import PyPDF2\n",
    "from tqdm.notebook import tqdm\n",
    "import re\n",
    "import json\n",
    "\n",
    "def read_pdfs_from_folder(folder_path):\n",
    "    pdf_list = []\n",
    "    \n",
    "    # Loop through all files in the specified folder\n",
    "    for filename in tqdm(os.listdir(folder_path)):\n",
    "        if filename.endswith('.pdf'):\n",
    "            file_path = os.path.join(folder_path, filename)\n",
    "            \n",
    "            # Open each PDF file\n",
    "            with open(file_path, 'rb') as file:\n",
    "                reader = PyPDF2.PdfReader(file)\n",
    "                content = \"\"\n",
    "                \n",
    "                # Read each page's content and append it to a string\n",
    "                for page_num in range(len(reader.pages)):\n",
    "                    page = reader.pages[page_num]\n",
    "                    content += page.extract_text()\n",
    "                \n",
    "                # Add the PDF content to the list\n",
    "                pdf_list.append({\"content\": content, \"filename\": filename})\n",
    "    \n",
    "    return pdf_list\n",
    "\n",
    "folder_path = \"./rag_data\"\n",
    "\n",
    "# all_documents = read_pdfs_from_folder(folder_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af4cc9b3-1131-4392-8ee9-7c019b353cfb",
   "metadata": {},
   "source": [
    "## Read Web URLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d74db54-5f22-47ee-bfd4-6a987be88ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "import requests\n",
    "\n",
    "def fetch_url_content(url: str) -> Optional[str]:\n",
    "    \"\"\"\n",
    "    Fetches content from a URL by performing an HTTP GET request.\n",
    "\n",
    "    Parameters:\n",
    "        url (str): The endpoint or URL to fetch content from.\n",
    "\n",
    "    Returns:\n",
    "        Optional[str]: The content retrieved from the URL as a string,\n",
    "                       or None if the request fails.\n",
    "    \"\"\"\n",
    "    prefix_url: str = \"https://r.jina.ai/\"\n",
    "    full_url: str = prefix_url + url  # Concatenate the prefix URL with the provided URL\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(full_url)  # Perform a GET request\n",
    "        if response.status_code == 200:\n",
    "            return response.content.decode('utf-8')  # Return the content of the response as a string\n",
    "        else:\n",
    "            print(f\"Error: HTTP GET request failed with status code {response.status_code}\")\n",
    "            return None\n",
    "    except requests.RequestException as e:\n",
    "        print(f\"Error: Failed to fetch URL {full_url}. Exception: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ceed779-8cc4-4b76-8f87-46138a9c24b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Content retrieved successfully:\n"
     ]
    }
   ],
   "source": [
    "# Replace this with the specific endpoint or URL you want to fetch\n",
    "url: str = \"https://em360tech.com/tech-article/what-is-llama-3\"  \n",
    "content: Optional[str] = fetch_url_content(url)\n",
    "\n",
    "\n",
    "if content is not None:\n",
    "    print(\"Content retrieved successfully:\")\n",
    "else:\n",
    "    print(\"Failed to retrieve content from the specified URL.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fde00dd-2d9e-4fa6-b006-0ee0aac53082",
   "metadata": {},
   "source": [
    "## Split the texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5c005dd7-c84f-4269-a4b5-9db5c5cbad7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import MarkdownHeaderTextSplitter\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from litellm import completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ae087266-156b-4a10-ba22-26bd0cb2e2b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_size = 150\n",
    "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "            model_name=\"gpt-4\",\n",
    "            chunk_size=token_size,\n",
    "            chunk_overlap=0,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4b5d1d70-51cb-421c-9c60-d6f663831665",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    # Remove all newline characters\n",
    "    text = text.replace('\\n', ' ').replace('\\r', ' ')\n",
    "    \n",
    "    # Replace multiple spaces with a single space\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    \n",
    "    # Strip leading and trailing spaces\n",
    "    text = text.strip()\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2878fe14-0e33-4cd8-966a-57fc2d89c82e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total chunks: 58\n"
     ]
    }
   ],
   "source": [
    "text_chunks = text_splitter.split_text(content)\n",
    "print(f\"Total chunks: {len(text_chunks)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "6d95465d-0d3f-4912-a460-793db2c7f4dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Title: What is Meta\\'s Llama 3? Everything you Need to Know\\n\\nURL Source: https://em360tech.com/tech-article/what-is-llama-3\\n\\nMarkdown Content:\\nWhat is Meta\\'s Llama 3? Everything you Need to Know | Enterprise Tech News EM360Tech\\n===============          \\n\\n[Skip to main content](https://em360tech.com/tech-article/what-is-llama-3#main-content)\\n\\n[![Image 1: Home](https://em360tech.com/themes/custom/tech360/images/logos/site-logo-black-100.webp)](https://em360tech.com/ \"Home\")\\n\\nTopics\\n\\nAI Data Emerging Technologies Infrastructure Management Security In The News'"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_chunks[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "34c0593c-1853-40b9-8f4d-b018faaaa8e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embeddings(texts, model=\"text-embedding-3-small\", api_key=\"your-api-key\"):\n",
    "    # Define the API URL\n",
    "    url = \"https://api.openai.com/v1/embeddings\"\n",
    "    \n",
    "    # Prepare headers with the API key\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"Authorization\": f\"Bearer {api_key}\"\n",
    "    }\n",
    "    \n",
    "    # Prepare the request body\n",
    "    data = {\n",
    "        \"input\": texts,\n",
    "        \"model\": model\n",
    "    }\n",
    "    \n",
    "    # Send a POST request to the OpenAI API\n",
    "    response = requests.post(url, headers=headers, data=json.dumps(data))\n",
    "    \n",
    "    # Check if the request was successful\n",
    "    if response.status_code == 200:\n",
    "        # Return the embeddings from the response\n",
    "        return response.json()[\"data\"]\n",
    "    else:\n",
    "        # Print error if the request fails\n",
    "        print(f\"Error {response.status_code}: {response.text}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "75bca4ca-dd8f-4d50-bb5b-a8709db992eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENAI_API_KEY = os.environ.get(\"OPENAI_API_KEY\")\n",
    "\n",
    "embeddings_objects = get_embeddings(text_chunks, api_key=OPENAI_API_KEY)\n",
    "assert len(embeddings_objects) == len(text_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8cd91227-9914-463d-8f74-b7e9311bcb68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1536"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings = [obj[\"embedding\"] for obj in embeddings_objects]\n",
    "len(embeddings[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7b192fdd-d3ff-4f22-ac24-78bd0bf19917",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install qdrant-client\n",
    "\n",
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.models import VectorParams, Distance\n",
    "\n",
    "client = QdrantClient(\"http://localhost:6333\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4067f232-a15f-4871-929b-f24d17a2cf47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collection_name = \"agent_rag_index\"\n",
    "VECTOR_SIZE = 1536\n",
    "\n",
    "client.delete_collection(collection_name)\n",
    "\n",
    "client.create_collection(\n",
    "    collection_name=collection_name,\n",
    "    vectors_config=VectorParams(size=VECTOR_SIZE, distance=Distance.COSINE),\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6d6aa183-0878-42e6-be2a-15b940d4115e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ul': 'https://em360tech.com/tech-article/what-is-llama-3',\n",
       " 'content': 'Title: What is Meta\\'s Llama 3? Everything you Need to Know\\n\\nURL Source: https://em360tech.com/tech-article/what-is-llama-3\\n\\nMarkdown Content:\\nWhat is Meta\\'s Llama 3? Everything you Need to Know | Enterprise Tech News EM360Tech\\n===============          \\n\\n[Skip to main content](https://em360tech.com/tech-article/what-is-llama-3#main-content)\\n\\n[![Image 1: Home](https://em360tech.com/themes/custom/tech360/images/logos/site-logo-black-100.webp)](https://em360tech.com/ \"Home\")\\n\\nTopics\\n\\nAI Data Emerging Technologies Infrastructure Management Security In The News'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids = []\n",
    "payload = []\n",
    "\n",
    "for id, text in enumerate(text_chunks):\n",
    "    ids.append(id)\n",
    "    payload.append({\"ul\": url, \"content\": text})\n",
    "\n",
    "payload[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "58bff9a2-597d-4685-ad75-c17d7b7bd1b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.upload_collection(\n",
    "    collection_name=collection_name,\n",
    "    vectors=embeddings,\n",
    "    payload=payload,\n",
    "    ids=ids,\n",
    "    batch_size=256,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8f4c7937-3820-46ed-a2d2-6ad0a551012e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountResult(count=58)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.count(collection_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "ca41a21e-0989-4308-a9a4-7b135d6e04a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(text: str, top_k: int):\n",
    "    query_embedding = get_embeddings(text, api_key=OPENAI_API_KEY)[0][\"embedding\"]\n",
    "    \n",
    "    search_result = client.search(\n",
    "        collection_name=collection_name,\n",
    "        query_vector=query_embedding,\n",
    "        query_filter=None,  \n",
    "        limit=top_k\n",
    "    )\n",
    "    return search_result\n",
    "\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.payload[\"content\"] for doc in docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17a6db49-a39f-4c9a-ba77-0621173d6068",
   "metadata": {},
   "source": [
    "# Prompts\n",
    "\n",
    "1. First prompt will check to see if the *retrieved context* can answer the user question.\n",
    "2. Second prompt will get the context and question and generates the response."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a661fb9b-c61c-4f8f-bed3-71d3622464aa",
   "metadata": {},
   "source": [
    "## First Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "2b6cb2c1-8778-477b-9427-096ef14a2b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_system_prompt = \"\"\"Your job is decide if a given question can be answered with a given context. \n",
    "If context can answer the question return 1.\n",
    "If not return 0.\n",
    "\n",
    "Do not return anything else except for 0 or 1.\n",
    "\n",
    "Context: {context}\n",
    "\"\"\"\n",
    "\n",
    "user_prompt = \"\"\"\n",
    "Question: {question}\n",
    "\n",
    "Answer:\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c87da197-4516-47a5-8c78-2f5101a4488b",
   "metadata": {},
   "source": [
    "## Second Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "46f9c6e4-857b-4d1c-a12e-e5406d4326a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"You are an expert for answering questions. Answer the question according only to the given context.\n",
    "If question cannot be answered using the context, simply say I don't know. Do not make stuff up.\n",
    "Your answer MUST be informative, concise, and action driven. Your response must be in Markdown.\n",
    "\n",
    "Context: {context}\n",
    "\"\"\"\n",
    "\n",
    "user_prompt = \"\"\"\n",
    "Question: {question}\n",
    "\n",
    "Answer:\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6446152-ce5d-4b31-843d-3f8729d4f24c",
   "metadata": {},
   "source": [
    "## Ask questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "792c1523-b8b0-4723-99ce-7a2d01d7e9df",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"what is openai o1 model\"\n",
    "results = search(question, top_k=3)\n",
    "context = format_docs(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "0a20fbcb-2c1e-4fcc-ae94-c391b6981546",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0'"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = completion(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[{\"content\": decision_system_prompt.format(context=context),\"role\": \"system\"}, {\"content\": user_prompt.format(question=question),\"role\": \"user\"}],\n",
    "    max_tokens=500,\n",
    "    # format=\"json\"\n",
    "    \n",
    ")\n",
    "has_answer = response.choices[0].message.content\n",
    "has_answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef26d7b4-9f92-45d5-8f75-c5a8e8026824",
   "metadata": {},
   "source": [
    "# Check to see if retrieved context can answer the question or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "9213c5a5-c8f7-49cb-975b-dbdbc8320755",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown, display\n",
    "from duckduckgo_search import DDGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "58a0852e-2e07-4636-8f8d-050a269780d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: what is openai o1 model\n",
      "Context is NOT relevant. Searching online...\n",
      "Found online sources. Generating the response...\n",
      "Answer:\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "OpenAI o1 is a new large language model trained with reinforcement learning to perform complex reasoning tasks. It is designed to take more time to think before responding, allowing it to generate a thorough internal thought process. This model excels in advanced reasoning and is suitable for solving complex problems, including those in math and science. It aims to provide deep contextual understanding and support agentic workflows."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def format_search_results(results):\n",
    "    return \"\\n\\n\".join(doc[\"body\"] for doc in results)\n",
    "    \n",
    "\n",
    "print(f\"Question: {question}\")\n",
    "if has_answer == '1':\n",
    "    print(\"Context can answer the question\")\n",
    "    response = completion(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[{\"content\": system_prompt.format(context=context),\"role\": \"system\"}, {\"content\": user_prompt.format(question=question),\"role\": \"user\"}],\n",
    "        max_tokens=500\n",
    "    )\n",
    "    print(\"Answer:\")\n",
    "    display(Markdown(response.choices[0].message.content))\n",
    "else:\n",
    "    print(\"Context is NOT relevant. Searching online...\")\n",
    "    results = DDGS().text(question, max_results=5)\n",
    "    context = format_search_results(results)\n",
    "    print(\"Found online sources. Generating the response...\")\n",
    "    response = completion(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[{\"content\": system_prompt.format(context=context),\"role\": \"system\"}, {\"content\": user_prompt.format(question=question),\"role\": \"user\"}],\n",
    "        max_tokens=500\n",
    "    )\n",
    "    print(\"Answer:\")\n",
    "    display(Markdown(response.choices[0].message.content))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "e8d1a751-01d3-436c-865b-6174fe0a3afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -U duckduckgo_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "cb19a39a-bfd0-4dd0-ae35-d9d774fbe1c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'title': 'Introducing OpenAI o1', 'href': 'https://openai.com/index/introducing-openai-o1-preview/', 'body': \"OpenAI o1-mini. The o1 series excels at accurately generating and debugging complex code. To offer a more efficient solution for developers, we're also releasing OpenAI o1-mini, a faster, cheaper reasoning model that is particularly effective at coding. As a smaller model, o1-mini is 80% cheaper than o1-preview, making it a powerful, cost ...\"}, {'title': 'Learning to Reason with LLMs - OpenAI', 'href': 'https://openai.com/index/learning-to-reason-with-llms/', 'body': 'We are introducing OpenAI o1, a new large language model trained with reinforcement learning to perform complex reasoning. o1 thinks before it answers—it can produce a long internal chain of thought before responding to the user. We are introducing OpenAI o1, a new large language model trained with reinforcement learning to perform complex ...'}, {'title': 'OpenAI o1 Hub | OpenAI', 'href': 'https://openai.com/o1/', 'body': \"Here is the latest news on o1 research, product and other updates. ... Safety; Company; Introducing OpenAI o1. We've developed a new series of AI models designed to spend more time thinking before they respond. Here is the latest news on o1 research, product and other updates. Try it in ChatGPT Plus (opens in a new window) ...\"}, {'title': \"Introducing o1: OpenAI's new reasoning model series for developers and ...\", 'href': 'https://azure.microsoft.com/en-us/blog/introducing-o1-openais-new-reasoning-model-series-for-developers-and-enterprises-on-azure/', 'body': \"To better understand o1-preview and o1-mini's place in our model lineup, here's a quick overview of the key models powering Azure OpenAI Service: o1-preview: Focused on advanced reasoning and solving complex problems, including math and science tasks. Ideal for applications that require deep contextual understanding and agentic workflows.\"}, {'title': 'OpenAI Unveils o1 ChatGPT Model That Can Reason Through Math and ...', 'href': 'https://www.nytimes.com/2024/09/12/technology/openai-chatgpt-math.html', 'body': 'OpenAI is in talks to raise about $6.5 billion as part of a deal that would value the company in the vicinity of $150 billion, a nearly $70 billion increase from its valuation nine months ago.'}]\n"
     ]
    }
   ],
   "source": [
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "26d5fa24-8c36-4b22-9c51-9102a9b4db5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File downloaded successfully\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "# URL of the file\n",
    "url = 'https://chrt.fm/track/46DD7B/media.transistor.fm/7387a8a4/cefc95d5.mp3?download=true&src=player'\n",
    "\n",
    "# Send a HTTP request to the URL\n",
    "response = requests.get(url)\n",
    "\n",
    "# Check if the request was successful\n",
    "if response.status_code == 200:\n",
    "    # Open a local file in binary write mode\n",
    "    with open('audio_file.mp3', 'wb') as file:\n",
    "        # Write the content of the response to the file\n",
    "        file.write(response.content)\n",
    "    print('File downloaded successfully')\n",
    "else:\n",
    "    print('Failed to download file. Status code:', response.status_code)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05c2a24c-9d78-4905-8c3a-1a40f20f8119",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
